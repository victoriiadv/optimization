{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtS8xRTZ2iZk"
      },
      "outputs": [],
      "source": [
        "#библиотеки\n",
        "\n",
        "import sympy as sp # для символьных вычислений\n",
        "import numpy as np # для вычислений"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#инициализация глобальных переменных\n",
        "\n",
        "x, y, z = sp.symbols('x y z')\n",
        "alpha = sp.Symbol('\\u03B1')\n",
        "beta = sp.Symbol('\\u03B2') #длина шага\n",
        "lmbd = sp.Symbol('\\u03BB') #коэффициент дробления\n",
        "eps = sp.Symbol('\\u03B5') #точность приближения\n",
        "\n",
        "f = 8*x**2 + 8*x*y - 2*x*z + 6*y**2 + 4*y*z + 6*z**2 + 4*x - 14*y - 18*z + 134\n",
        "eps = 0.03\n",
        "beta = 0.5\n",
        "lmbd = 0.5\n",
        "\n",
        "\n",
        "#начальное приближение\n",
        "x0 = 0.223\n",
        "y0 = 0.54\n",
        "z0 = 0.178"
      ],
      "metadata": {
        "id": "NGqElnHC3Upt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# функции\n",
        "\n",
        "'''\n",
        "функция gradient для вычисления градиента функции в точке (x, y, z)\n",
        "  вход: функция f, координаты точки [x, y, z]\n",
        "  выход: вектор градиента в данной точке\n",
        "'''\n",
        "def gradient(f, point):\n",
        "  grad = np.array([\n",
        "      sp.diff(f, x).subs({x: point[0], y: point[1], z: point[2]}),\n",
        "      sp.diff(f, y).subs({x: point[0], y: point[1], z: point[2]}),\n",
        "      sp.diff(f, z).subs({x: point[0], y: point[1], z: point[2]})\n",
        "  ])\n",
        "  return grad\n",
        "\n",
        "\n",
        "'''\n",
        "функция gradient_descent метода градиентного спуска с дроблением шага\n",
        "  вход: функция f, параметры beta, lambda, epsilon; начальное приближение x0, y0, z0\n",
        "  выход: названия метода, количества итераций k, координат x_k, градиента в точке x_k, значения f(x_k), погрешности\n",
        "'''\n",
        "def gradient_descent(f, beta, lmbd, eps, x0, y0, z0):\n",
        "  x_k = [x0, y0, z0]\n",
        "  k = 0\n",
        "  while np.max( np.abs( gradient(f, x_k))) >= eps:\n",
        "    alpha_k = beta\n",
        "    h_k = - gradient(f, x_k)\n",
        "    x_k_new = np.array(x_k) + alpha_k * h_k\n",
        "    while f.subs({x: x_k[0], y: x_k[1], z: x_k[2]}) <= f.subs({x: x_k_new[0], y: x_k_new[1], z: x_k_new[2]}):\n",
        "      alpha_k *= lmbd\n",
        "      x_k_new = np.array(x_k) + alpha_k * h_k\n",
        "    k += 1\n",
        "    x_k = x_k_new.tolist()\n",
        "\n",
        "  x_analytical = np.array([-20/23, 67/46, 20/23])\n",
        "  fault = np.abs(f.subs({x: x_analytical[0], y: x_analytical[1], z: x_analytical[2]}) -\n",
        "                 f.subs({x: x_k[0], y: x_k[1], z: x_k[2]}))\n",
        "  print (\"Gradient descent\\nIteration: \", k,\"\\nPoint:     \", x_k, \"\\nGradient:  \", gradient(f, x_k), \"\\nValue:     \", f.subs({x: x_k[0], y: x_k[1], z: x_k[2]}),\n",
        "         \"\\nFault:     \", fault)\n",
        "\n",
        "\n",
        "'''\n",
        "функция Hessian_matrix для нахождения матрицы вторых производных\n",
        "  вход: функция f\n",
        "  выход: матрица вторых производных\n",
        "'''\n",
        "def Hessian_matrix(f):\n",
        "  A = [[0]*3 for i in range(3)]\n",
        "  A[0][0] = sp.diff(sp.diff(f, x), x)\n",
        "  A[0][1] = A[1][0] = sp.diff(sp.diff(f, x), y)\n",
        "  A[0][2] = A[2][0] = sp.diff(sp.diff(f, x), z)\n",
        "  A[1][1] = sp.diff(sp.diff(f, y), y)\n",
        "  A[1][2] = A[2][1] = sp.diff(sp.diff(f, y), z)\n",
        "  A[2][2] = sp.diff(sp.diff(f, z), z)\n",
        "  return A\n",
        "\n",
        "\n",
        "'''\n",
        "функция min_alpha для нахождения оптимального альфа (для минимизации f)\n",
        "  вход: функция f, координаты точки x_k (список), координаты h_k (список)\n",
        "  выход: оптимальное значение альфа\n",
        "'''\n",
        "def min_alpha (f, x_k, h_k):\n",
        "    alpha_k = sp.Symbol('alpha_k')\n",
        "    f_alpha = f.subs({x: x_k[0] + alpha_k * h_k[0], y: x_k[1] + alpha_k * h_k[1], z: x_k[2] + alpha_k * h_k[2]})\n",
        "\n",
        "    alpha_arr = sp.solve(sp.diff(f_alpha, alpha_k), alpha_k)\n",
        "    f_alpha_val = []\n",
        "    for alpha in alpha_arr:\n",
        "      f_alpha_val.append(f_alpha.subs(alpha_k, alpha))\n",
        "\n",
        "    return alpha_arr[f_alpha_val.index(min(f_alpha_val))]\n",
        "\n",
        "\n",
        "'''\n",
        "функция conjugate_gradients - метод сопряженных градиентов\n",
        "  вход: функция f, координаты x0, y0, z0 (начального приближения)\n",
        "  выход: вывод названия метода, количества итераций k, координат x_k, градиента в точке x_k, значения f(x_k), погрешности\n",
        "'''\n",
        "def conjugate_gradients (f, x0, y0, z0):\n",
        "  k = 0\n",
        "  x_k = np.array([x0, y0, z0])\n",
        "  h_k = - gradient(f, x_k)\n",
        "\n",
        "  while np.max(np.abs(gradient(f, x_k))) >= 10**(-5) :\n",
        "\n",
        "    x_k_new = x_k + min_alpha(f, x_k, h_k) * h_k\n",
        "\n",
        "    conj_beta_k = np.dot(Hessian_matrix(f) @ h_k, gradient(f, x_k_new)) / np.dot(Hessian_matrix(f) @ h_k, h_k)\n",
        "    h_k_new = - gradient(f, x_k_new) + conj_beta_k * h_k\n",
        "\n",
        "    k += 1\n",
        "    x_k = x_k_new\n",
        "    h_k = h_k_new\n",
        "\n",
        "  x_analytical = np.array([-20/23, 67/46, 20/23])\n",
        "  fault = np.abs(f.subs({x: x_analytical[0], y: x_analytical[1], z: x_analytical[2]}) -\n",
        "                 f.subs({x: x_k[0], y: x_k[1], z: x_k[2]}))\n",
        "  print (\"Сonjugate gradients \\nIteration: \", k,\"\\nPoint:     \", x_k, \"\\nGradient:  \", gradient(f, x_k), \"\\nValue:     \", f.subs({x: x_k[0], y: x_k[1], z: x_k[2]}),\n",
        "         \"\\nFault:     \", fault)"
      ],
      "metadata": {
        "id": "suhv0Xz_3YTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_descent(f, beta, lmbd, eps, x0, y0, z0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amVDimWDEDxb",
        "outputId": "9b9d0feb-c2df-4bb1-96d2-0e5780196a0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient descent\n",
            "Iteration:  14 \n",
            "Point:      [-0.865877460286087, 1.45297292323237, 0.872279623414215] \n",
            "Gradient:   [0.0251847744531712 -0.00222610984335248 0.0110020944722464] \n",
            "Value:      114.239195754551 \n",
            "Fault:      6.53197682396467e-5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conjugate_gradients (f, x0, y0, z0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWsuBMqU31a8",
        "outputId": "adcd321c-7359-4774-9287-3fa2fedb1e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сonjugate gradients \n",
            "Iteration:  3 \n",
            "Point:      [-0.869565217391304 1.45652173913044 0.869565217391305] \n",
            "Gradient:   [6.66133814775094e-15 7.99360577730113e-15 8.88178419700125e-15] \n",
            "Value:      114.239130434783 \n",
            "Fault:      1.42108547152020e-14\n"
          ]
        }
      ]
    }
  ]
}